{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:00.276413Z",
     "start_time": "2025-01-28T18:55:00.260549Z"
    }
   },
   "source": [
    "import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n",
    "sys.executable"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.6/lib64:~/.virtualenvs/dopamine/lib/python3.10/site-packages/nvidia/cudnn//lib:/home/eop/.mujoco/mujoco210/bin:/usr/lib/nvidia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/eop/code/CORL/venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:02.112009Z",
     "start_time": "2025-01-28T18:55:00.306085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import uuid\n",
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import d4rl\n",
    "import gym\n",
    "import numpy as np\n",
    "import pyrallis\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from tqdm import tqdm, trange\n",
    "import multiprocessing\n",
    "\n",
    "multiprocessing.set_start_method('spawn', force=True)"
   ],
   "id": "4f4786aa65e3996d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "env_name = 'halfcheetah-medium-v2'\n",
    "env = gym.make(env_name)\n",
    "dataset = env.get_dataset()\n",
    "torch.set_default_device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:05.000638Z",
     "start_time": "2025-01-28T18:55:02.148311Z"
    }
   },
   "id": "6ffc9688bf8b4a8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eop/code/CORL/venv/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 13.15it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from algorithms.offline.knn import load_d4rl_trajectories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:05.150553Z",
     "start_time": "2025-01-28T18:55:05.108587Z"
    }
   },
   "id": "7b3b44e1b24b2108",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "trajs, infos = load_d4rl_trajectories(env_name)\n",
    "obs_shape = trajs[0]['observations'].shape[1]\n",
    "action_shape=trajs[0]['actions'].shape[1]\n",
    "obs_mean = infos['obs_mean']\n",
    "obs_std = infos['obs_std']\n",
    "print(obs_shape, action_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:08.759476Z",
     "start_time": "2025-01-28T18:55:05.175940Z"
    }
   },
   "id": "93fabbdff1f6bf34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eop/code/CORL/venv/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 12.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing trajectories:   0%|          | 0/1000000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01ad3086c96b4d2794867d0ccd4f1bd1"
      },
      "application/json": {
       "n": 0,
       "total": 1000000,
       "elapsed": 0.0035004615783691406,
       "ncols": null,
       "nrows": 30,
       "prefix": "Processing trajectories",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 6\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "infos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:08.806880Z",
     "start_time": "2025-01-28T18:55:08.786426Z"
    }
   },
   "id": "534c9ba88b08d594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs_mean': array([[-0.06845774,  0.01641455, -0.18354906, -0.27624607, -0.34061527,\n",
       "         -0.09339716, -0.21321271, -0.08774239,  5.1730075 , -0.04275195,\n",
       "         -0.03610836,  0.14053793,  0.06049833,  0.09550975,  0.067391  ,\n",
       "          0.00562739,  0.01338279]], dtype=float32),\n",
       " 'obs_std': array([[ 0.07472999,  0.30234998,  0.3020731 ,  0.34417078,  0.17619242,\n",
       "          0.5072056 ,  0.25670078,  0.32948127,  1.2574149 ,  0.7600542 ,\n",
       "          1.9800916 ,  6.5653625 ,  7.4663677 ,  4.472223  , 10.566964  ,\n",
       "          5.6719327 ,  7.498259  ]], dtype=float32),\n",
       " 'reward_mean': array([4.7703357], dtype=float32),\n",
       " 'reward_std': array([1.2101753], dtype=float32),\n",
       " 'traj_lens': array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, trajs, infos):\n",
    "        self.trajs = trajs\n",
    "        self.infos = infos\n",
    "        self.obs_mean = infos['obs_mean']\n",
    "        self.obs_std = infos['obs_std']\n",
    "        self.traj_lens = np.array([traj['observations'].shape[0] for traj in trajs])\n",
    "        self.rollout_length = 5\n",
    "        for traj in trajs:\n",
    "            traj['observations'] = (traj['observations'] - self.obs_mean) / self.obs_std\n",
    "            traj['rewards'] = (traj['rewards'] - traj['rewards'].mean()) / traj['rewards'].std()\n",
    "\n",
    "\n",
    "        self.len = sum(self.traj_lens) - (self.rollout_length + 1) * len(trajs)\n",
    "        self.index_to_traj = np.concatenate([np.full(traj_len - self.rollout_length - 1, i) for i, traj_len in enumerate(self.traj_lens)])\n",
    "        self.index_to_traj_ind = np.concatenate([np.arange(0, traj_len - self.rollout_length - 1) for traj_len in self.traj_lens])\n",
    "\n",
    "        assert len(self.index_to_traj) == self.len, f\"{len(self.index_to_traj)} != {self.len}\"\n",
    "        assert len(self.index_to_traj_ind) == self.len, f\"{len(self.index_to_traj_ind)} != {self.len}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        traj = self.trajs[self.index_to_traj[idx]]\n",
    "        ind = self.index_to_traj_ind[idx]\n",
    "        indices = np.arange(ind, ind + self.rollout_length)\n",
    "        return {\n",
    "            'observations': traj['observations'][indices],\n",
    "            'actions': traj['actions'][indices],\n",
    "            'next_observations': traj['observations'][indices + 1],\n",
    "            'rewards': traj['rewards'][indices],\n",
    "        }\n",
    "\n",
    "all_data = MyDataset(trajs, infos)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:08.907443Z",
     "start_time": "2025-01-28T18:55:08.847720Z"
    }
   },
   "id": "7d6f202e3337b2df",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input: int, hidden_dim: int, output: int, num_layers: int = 2):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.input = input\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output = output\n",
    "        self.num_layers = num_layers\n",
    "        self.input_fc = nn.Linear(input, hidden_dim)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers)])\n",
    "        self.output_fc = nn.Linear(hidden_dim, output)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer_norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(num_layers)])\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for layer in self.fcs:\n",
    "            nn.init.orthogonal_(layer.weight, nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        nn.init.orthogonal_(self.output_fc.weight, 1.0)\n",
    "        nn.init.zeros_(self.output_fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_fc(x))\n",
    "        for fc, layer_norm in zip(self.fcs, self.layer_norms):\n",
    "            x = self.activation(layer_norm(fc(x)))\n",
    "        return self.output_fc(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, obs_shape, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = MLPModel(obs_shape, hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class InvModel(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, action_shape):\n",
    "        super(InvModel, self).__init__()\n",
    "        self.model = MLPModel(2*latent_dim, hidden_dim, action_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, action_shape):\n",
    "        super(ForwardModel, self).__init__()\n",
    "        self.model = MLPModel(latent_dim + action_shape, hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, obs, action):\n",
    "        return self.model(torch.cat([obs, action], dim=-1))\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, latent_dim, action_shape, hidden_dim):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.model = MLPModel(latent_dim * 2 + action_shape, hidden_dim, 1)\n",
    "\n",
    "    def forward(self, z, a, z_next):\n",
    "        return self.model(torch.cat([z, a, z_next], dim=-1))\n",
    "\n",
    "\n",
    "hidden_dim = 128\n",
    "latent_dim = 16\n",
    "encoder = Encoder(obs_shape=obs_shape, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "target_encoder = Encoder(obs_shape=obs_shape, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "inv_model = InvModel(latent_dim=latent_dim, hidden_dim=hidden_dim, action_shape=action_shape)\n",
    "forward_model = ForwardModel(latent_dim=latent_dim, hidden_dim=hidden_dim, action_shape=action_shape)\n",
    "reward_model = RewardModel(latent_dim=latent_dim, hidden_dim=hidden_dim, action_shape=action_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:10.134713Z",
     "start_time": "2025-01-28T18:55:08.924952Z"
    }
   },
   "id": "1af456c6243c75f6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "batch_size = 256\n",
    "target_ema = 0.995\n",
    "grad_clip_norm = 1\n",
    "epochs = 5\n",
    "train_size = int(0.8 * len(trajs))\n",
    "indices = np.random.permutation(len(trajs))\n",
    "trajs_np = np.array(trajs)\n",
    "train_idx, val_idx = indices[:train_size], indices[train_size:]\n",
    "dataset, val_set = MyDataset(trajs_np[train_idx], infos), MyDataset(trajs_np[val_idx], infos)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "optimizer = AdamW(list(encoder.parameters()) + list(inv_model.parameters()) + list(forward_model.parameters()) + list(reward_model.parameters()), lr=1e-3)\n",
    "\n",
    "def cosine_loss(z, z_next):\n",
    "    return -F.cosine_similarity(z, z_next, dim=-1).mean()\n",
    "\n",
    "def mse_loss(z, z_next):\n",
    "    return F.mse_loss(z, z_next)\n",
    "\n",
    "model_loss_fn = mse_loss\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def train_step(batch):\n",
    "    obs = batch['observations']\n",
    "    act = batch['actions']\n",
    "    next_obs = batch['next_observations']\n",
    "    rewards = batch['rewards']\n",
    "\n",
    "    z_enc = encoder(obs) # (batch, seq_len, latent_dim)\n",
    "    with torch.no_grad():\n",
    "        z_next_tar = target_encoder(next_obs) # (batch, seq_len, latent_dim)\n",
    "\n",
    "    # rollout\n",
    "    z_next = torch.zeros_like(z_next_tar)\n",
    "    z = z_enc[:, 0]\n",
    "    action_pred = torch.zeros_like(act) # (batch, seq_len, action_dim)\n",
    "    for i in range(0, obs.shape[1]):\n",
    "        z_pred = forward_model(z, act[:, i]) # (batch, latent_dim)\n",
    "        action_offset = torch.randint(0, z_next_tar.shape[1] - i, (z_next_tar.shape[0],)) # (batch,)\n",
    "        batch_indices = torch.arange(z_next_tar.shape[0], device=z_next_tar.device)\n",
    "        selected_indices = i + action_offset\n",
    "        action_pred[:, i] = inv_model(torch.cat([z_enc[:, i], z_next_tar[batch_indices, selected_indices]], dim=-1))\n",
    "        z_next[:, i] = z_pred\n",
    "        z = z_pred\n",
    "\n",
    "    model_loss = model_loss_fn(z_next, z_next_tar)\n",
    "    action_loss = F.mse_loss(action_pred, act)\n",
    "    reward_pred = reward_model(z_enc, act, z_next_tar).squeeze(-1)\n",
    "    reward_loss = F.mse_loss(reward_pred, rewards)\n",
    "    loss = model_loss + action_loss + reward_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=grad_clip_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(inv_model.parameters(), max_norm=grad_clip_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(forward_model.parameters(), max_norm=grad_clip_norm)\n",
    "    torch.nn.utils.clip_grad_norm_(reward_model.parameters(), max_norm=grad_clip_norm)\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update target encoder with exponential moving average\n",
    "    for param, target_param in zip(encoder.parameters(), target_encoder.parameters()):\n",
    "        target_param.data = target_param.data * target_ema + param.data * (1.0 - target_ema)\n",
    "    \n",
    "    return loss.item(), model_loss.item(), action_loss.item(), reward_loss.item()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:55:10.754577Z",
     "start_time": "2025-01-28T18:55:10.164698Z"
    }
   },
   "id": "9b61d159d65860d1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-28T18:55:10.769806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "model_losses = []\n",
    "action_losses = []\n",
    "reward_losses = []\n",
    "\n",
    "forward_model.train()\n",
    "reward_model.train()\n",
    "encoder.train()\n",
    "inv_model.train()\n",
    "\n",
    "target_encoder.eval()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for batch in tqdm(dataloader):\n",
    "        loss, model_loss, action_loss, reward_loss = train_step(batch)\n",
    "        losses.append(loss)\n",
    "        model_losses.append(model_loss)\n",
    "        action_losses.append(action_loss)\n",
    "        reward_losses.append(reward_loss)"
   ],
   "id": "e5cc62c12f61de52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3107/3107 [08:16<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████                                            | 1378/3107 [03:46<04:32,  6.33it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses, label='total')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(model_losses[100:], label='model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(action_losses, label='action')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(reward_losses, label='reward')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "74a6e72258b6f617",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# validate that model is accurate\n",
    "\n",
    "val_set_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "def plot_hists(loader):\n",
    "    model_loss_total = 0\n",
    "    model_loss_shuffle = 0\n",
    "    bins = np.linspace(0, 7, 100, endpoint=True)\n",
    "    bins = np.concatenate([bins, [10000]])\n",
    "    hists = dict()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            z = encoder(batch['observations'])\n",
    "            z_next = encoder(batch['next_observations'])\n",
    "            z_pred = forward_model(z, batch['actions'])\n",
    "            for i in range(z_next.shape[1]):\n",
    "                hists[i] = hists.get(i, np.zeros_like(bins[:-1]))\n",
    "                dist = torch.norm(z[0] - z_next[i], dim=-1)\n",
    "                hists[i] += np.histogram(dist.cpu().numpy(), bins=bins)[0]\n",
    "            hists[\"rand\"] = hists.get(\"rand\", np.zeros_like(bins[:-1]))\n",
    "            dist_rand = torch.norm(z[0] - z_next[torch.randperm(len(z))], dim=-1)\n",
    "            hists[\"rand\"] += np.histogram(dist_rand).cpu().numpy(), bins=bins)[0]\n",
    "\n",
    "            model_loss_total += model_loss_fn(z_pred, z_next)\n",
    "            model_loss_shuffle += model_loss_fn(z_pred, z_next[torch.randperm(len(z))])\n",
    "    print(\n",
    "        f\"Model loss: {model_loss_total / len(loader)}\\n\"\n",
    "        f\"Model loss (shuffle): {model_loss_shuffle / len(loader)}\"\n",
    "    )\n",
    "\n",
    "    plotting_bins = np.copy(bins)\n",
    "    plotting_bins[-1] = plotting_bins[-2] + 1\n",
    "    for key, val in hists.items():\n",
    "        if key in set(range(5, 1000)):\n",
    "            continue\n",
    "        val /= np.sum(val)\n",
    "        plt.stairs(val, plotting_bins, label=f\"Distance {key}\")\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.show()\n",
    "\n",
    "plot_hists(val_set_loader)\n",
    "plot_hists(dataloader)"
   ],
   "id": "d99e7271b580a7ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pynndescent import NNDescent\n",
    "from dataclasses import dataclass\n",
    "    \n",
    "num_obs = np.sum(infos['traj_lens'])\n",
    "\n",
    "obs_norm = np.zeros((num_obs, latent_dim), dtype=np.float32)\n",
    "z_next = np.zeros((num_obs, latent_dim), dtype=np.float32)\n",
    "\n",
    "returns = np.zeros(num_obs, dtype=np.float32)\n",
    "actions = np.zeros((num_obs, trajs[0]['actions'].shape[1]), dtype=np.float32)\n",
    "\n",
    "next_state_distance = 2\n",
    "ind = 0\n",
    "for traj in tqdm(trajs):\n",
    "    indices = slice(ind, ind+traj['observations'].shape[0] - next_state_distance)\n",
    "    obs = traj['observations']\n",
    "    z = encoder(torch.tensor(obs, dtype=torch.float32)).detach().cpu().numpy()\n",
    "    obs_norm[indices] = z[:-next_state_distance]\n",
    "    z_next[indices] = z[next_state_distance:]\n",
    "    returns[indices] = traj['returns'][:-next_state_distance]\n",
    "    actions[indices] = traj['actions'][:-next_state_distance]\n",
    "    ind += traj['observations'].shape[0] - next_state_distance"
   ],
   "metadata": {},
   "id": "cf948f9f88ecd65e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": "index = NNDescent(obs_norm, metric='euclidean')",
   "id": "3a71db5b8fb5ae22",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from algorithms.offline.knn import wrap_env\n",
    "\n",
    "eval_env = wrap_env(\n",
    "    env=gym.make(env_name),\n",
    "    state_mean=obs_mean,\n",
    "    state_std=obs_std,\n",
    "    reward_scale=1.0,\n",
    ")\n",
    "eval_episodes = 100\n",
    "k=1\n"
   ],
   "metadata": {},
   "id": "303bc0ad45bae283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx, dist = index.query(eval_env.reset(), k=500)\n",
    "idx.shape, idx, dist"
   ],
   "id": "e5c869e7524220e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def eval():\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    while not done:\n",
    "        z = encoder(torch.tensor(obs, dtype=torch.float32).unsqueeze(0)).detach().cpu().numpy()\n",
    "        idxs, dists = index.query(z[0], k=k)\n",
    "        neighbor_rets = returns[idxs]\n",
    "        ranks = neighbor_rets * np.exp(-1 * dists)\n",
    "        best_idx = idxs[0, np.argmax(ranks)]\n",
    "\n",
    "        action = actions[best_idx]\n",
    "        obs, reward, done, _ = eval_env.step(action)\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "eval_rets = [eval() for _ in trange(eval_episodes, desc=\"Evaluation\", leave=False)]\n",
    "np.mean(eval_rets), env.get_normalized_score(np.mean(eval_rets)) * 100.0"
   ],
   "id": "8fa1b28ee74f319c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def eval_inv_model():\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    while not done:\n",
    "        z = encoder(torch.tensor(obs, dtype=torch.float32).unsqueeze(0)).detach().cpu().numpy()[0]\n",
    "        idxs, dists = index.query(z, k=k)\n",
    "        neighbor_rets = returns[idxs]\n",
    "        ranks = neighbor_rets * np.exp(-1 * dists)\n",
    "        best_idx = idxs[0, np.argmax(ranks)]\n",
    "\n",
    "        action = inv_model(torch.tensor(np.concatenate([z, z_next[best_idx][None,:]], axis=-1), dtype=torch.float32).unsqueeze(0)).detach().cpu().numpy()\n",
    "        obs, reward, done, _ = eval_env.step(action.squeeze())\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "eval_rets_inv = [eval_inv_model() for _ in trange(eval_episodes, desc=\"Evaluation\", leave=False)]\n",
    "np.mean(eval_rets_inv), env.get_normalized_score(np.mean(eval_rets_inv)) * 100.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7cb9fd3758c4a96",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "2fde76f09220764c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6288fbe3492159a1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
